{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare_dataset2\n",
    "\n",
    "To prepare a new datatset for training the network for inverse kinematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zeno_face_tracker_helpers import *\n",
    "try:\n",
    "    from ConfigParser import ConfigParser    # If using Python 2.7\n",
    "except ImportError:\n",
    "    from configparser import ConfigParser    # If using Python 3.5\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "sys.path.append(os.path.realpath(config.get('zeno_interface', 'repository_path')))\n",
    "from video_sources import *\n",
    "from zeno_interface import *\n",
    "sys.path.append(os.path.realpath(config.get('facial_landmark_tracker', 'repository_path')))\n",
    "from ibug_face_tracker import *\n",
    "from zeno_face_tracker import *\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get landmarks for the CK images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "ck_data_folder = os.path.realpath('./dataset3/sorted_set_testing')\n",
    "ck_images = glob.glob(os.path.join(ck_data_folder, './*/*.png'))\n",
    "ck_images = [x for x in ck_images if not '_rendering.png' in x and not '_zeno.png' in x]\n",
    "\n",
    "ert_model_path = config.get('facial_landmark_tracker', 'ert_model_path')\n",
    "auxiliary_model_path = config.get('facial_landmark_tracker', 'auxiliary_model_path')\n",
    "tracker = FaceTracker(ert_model_path, auxiliary_model_path)\n",
    "tracker.hard_failure_threshold = -1e6\n",
    "tracker.face_detection_scale = 2.0\n",
    "tracker.minimum_face_size = 50\n",
    "\n",
    "ck_data = []\n",
    "for image_file in ck_images:\n",
    "    image = cv2.imread(image_file)\n",
    "    tracker.reset()\n",
    "    tracker.track(image)\n",
    "    if tracker.has_facial_landmarks:\n",
    "        sample = {}\n",
    "        sample['landmarks'] = tracker.facial_landmarks\n",
    "        sample['eye_points'] = tracker.eye_landmarks\n",
    "        sample['head_pose'] = (tracker.pitch, tracker.yaw, tracker.roll)\n",
    "        sample['image_file'] = image_file\n",
    "        tracker.plot_current_result(image, plot_head_pose=False)\n",
    "        rendering_file = os.path.splitext(image_file)[0] + '_rendering.png'\n",
    "        cv2.imwrite(rendering_file, image)\n",
    "        ck_data.append(sample)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "anchors = [int(x) for x in config.get('data_organisation', 'alignment_anchors').strip().replace(\n",
    "    ' ', '').replace('\\'', '').replace('\\\"', '').split(',') if len(x) > 0]\n",
    "\n",
    "for sample in ck_data:\n",
    "    left_iris = sample['eye_points'][1:6].mean(axis=0)\n",
    "    right_iris = sample['eye_points'][8:13].mean(axis=0)\n",
    "    all_landmarks = np.vstack((sample['landmarks'], left_iris, right_iris))\n",
    "    \n",
    "    transform = compute_rigid_alignment_parameters(all_landmarks[anchors], \n",
    "                                                   model['mean_shape'][anchors])\n",
    "    aligned_landmarks = apply_rigid_alignment_parameters(all_landmarks, *transform)\n",
    "    displacement = aligned_landmarks - model['neutral_shape']\n",
    "\n",
    "    flattened_displacement = np.divide(displacement.flatten() - model['multipie_mean'], model['multipie_std'])\n",
    "    flattened_displacement_recon = np.matmul(np.matmul(flattened_displacement, \n",
    "                                                       model['multipie_pca_basis']), \n",
    "                                             model['multipie_pca_basis'].T)\n",
    "    feature = np.matmul(flattened_displacement_recon, model['pca_basis'])\n",
    "    sample['actuator_values'] = np.matmul(feature.tolist() + [1], model['lr_coefs'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to zeno at 127.0.0.1.\n",
      "Lanmark tracker initialised.\n",
      "Webcam #0 opened.\n",
      "1 of 365 samples captured.\n",
      "2 of 365 samples captured.\n",
      "3 of 365 samples captured.\n",
      "4 of 365 samples captured.\n",
      "5 of 365 samples captured.\n",
      "6 of 365 samples captured.\n",
      "7 of 365 samples captured.\n",
      "8 of 365 samples captured.\n",
      "9 of 365 samples captured.\n",
      "10 of 365 samples captured.\n",
      "11 of 365 samples captured.\n",
      "12 of 365 samples captured.\n",
      "13 of 365 samples captured.\n",
      "14 of 365 samples captured.\n",
      "15 of 365 samples captured.\n",
      "16 of 365 samples captured.\n",
      "17 of 365 samples captured.\n",
      "18 of 365 samples captured.\n",
      "19 of 365 samples captured.\n",
      "20 of 365 samples captured.\n",
      "21 of 365 samples captured.\n",
      "22 of 365 samples captured.\n",
      "23 of 365 samples captured.\n",
      "24 of 365 samples captured.\n",
      "25 of 365 samples captured.\n",
      "26 of 365 samples captured.\n",
      "27 of 365 samples captured.\n",
      "28 of 365 samples captured.\n",
      "29 of 365 samples captured.\n",
      "30 of 365 samples captured.\n",
      "31 of 365 samples captured.\n",
      "32 of 365 samples captured.\n",
      "33 of 365 samples captured.\n",
      "34 of 365 samples captured.\n",
      "35 of 365 samples captured.\n",
      "36 of 365 samples captured.\n",
      "37 of 365 samples captured.\n",
      "38 of 365 samples captured.\n",
      "39 of 365 samples captured.\n",
      "40 of 365 samples captured.\n",
      "41 of 365 samples captured.\n",
      "42 of 365 samples captured.\n",
      "43 of 365 samples captured.\n",
      "44 of 365 samples captured.\n",
      "45 of 365 samples captured.\n",
      "46 of 365 samples captured.\n",
      "47 of 365 samples captured.\n",
      "48 of 365 samples captured.\n",
      "49 of 365 samples captured.\n",
      "50 of 365 samples captured.\n",
      "51 of 365 samples captured.\n",
      "52 of 365 samples captured.\n",
      "53 of 365 samples captured.\n",
      "54 of 365 samples captured.\n",
      "55 of 365 samples captured.\n",
      "56 of 365 samples captured.\n",
      "57 of 365 samples captured.\n",
      "58 of 365 samples captured.\n",
      "59 of 365 samples captured.\n",
      "60 of 365 samples captured.\n",
      "61 of 365 samples captured.\n",
      "62 of 365 samples captured.\n",
      "63 of 365 samples captured.\n",
      "64 of 365 samples captured.\n",
      "65 of 365 samples captured.\n",
      "66 of 365 samples captured.\n",
      "67 of 365 samples captured.\n",
      "68 of 365 samples captured.\n",
      "69 of 365 samples captured.\n",
      "70 of 365 samples captured.\n",
      "71 of 365 samples captured.\n",
      "72 of 365 samples captured.\n",
      "73 of 365 samples captured.\n",
      "74 of 365 samples captured.\n",
      "75 of 365 samples captured.\n",
      "76 of 365 samples captured.\n",
      "77 of 365 samples captured.\n",
      "78 of 365 samples captured.\n",
      "79 of 365 samples captured.\n",
      "80 of 365 samples captured.\n",
      "81 of 365 samples captured.\n",
      "82 of 365 samples captured.\n",
      "83 of 365 samples captured.\n",
      "84 of 365 samples captured.\n",
      "85 of 365 samples captured.\n",
      "86 of 365 samples captured.\n",
      "87 of 365 samples captured.\n",
      "88 of 365 samples captured.\n",
      "89 of 365 samples captured.\n",
      "90 of 365 samples captured.\n",
      "91 of 365 samples captured.\n",
      "92 of 365 samples captured.\n",
      "93 of 365 samples captured.\n",
      "94 of 365 samples captured.\n",
      "95 of 365 samples captured.\n",
      "96 of 365 samples captured.\n",
      "97 of 365 samples captured.\n",
      "98 of 365 samples captured.\n",
      "99 of 365 samples captured.\n",
      "100 of 365 samples captured.\n",
      "101 of 365 samples captured.\n",
      "102 of 365 samples captured.\n",
      "103 of 365 samples captured.\n",
      "104 of 365 samples captured.\n",
      "105 of 365 samples captured.\n",
      "106 of 365 samples captured.\n",
      "107 of 365 samples captured.\n",
      "108 of 365 samples captured.\n",
      "109 of 365 samples captured.\n",
      "110 of 365 samples captured.\n",
      "111 of 365 samples captured.\n",
      "112 of 365 samples captured.\n",
      "113 of 365 samples captured.\n",
      "114 of 365 samples captured.\n",
      "115 of 365 samples captured.\n",
      "116 of 365 samples captured.\n",
      "117 of 365 samples captured.\n",
      "118 of 365 samples captured.\n",
      "119 of 365 samples captured.\n",
      "120 of 365 samples captured.\n",
      "121 of 365 samples captured.\n",
      "122 of 365 samples captured.\n",
      "123 of 365 samples captured.\n",
      "124 of 365 samples captured.\n",
      "125 of 365 samples captured.\n",
      "126 of 365 samples captured.\n",
      "127 of 365 samples captured.\n",
      "128 of 365 samples captured.\n",
      "129 of 365 samples captured.\n",
      "130 of 365 samples captured.\n",
      "131 of 365 samples captured.\n",
      "132 of 365 samples captured.\n",
      "133 of 365 samples captured.\n",
      "134 of 365 samples captured.\n",
      "135 of 365 samples captured.\n",
      "136 of 365 samples captured.\n",
      "137 of 365 samples captured.\n",
      "138 of 365 samples captured.\n",
      "139 of 365 samples captured.\n",
      "140 of 365 samples captured.\n",
      "141 of 365 samples captured.\n",
      "142 of 365 samples captured.\n",
      "143 of 365 samples captured.\n",
      "144 of 365 samples captured.\n",
      "145 of 365 samples captured.\n",
      "146 of 365 samples captured.\n",
      "147 of 365 samples captured.\n",
      "148 of 365 samples captured.\n",
      "149 of 365 samples captured.\n",
      "150 of 365 samples captured.\n",
      "151 of 365 samples captured.\n",
      "152 of 365 samples captured.\n",
      "153 of 365 samples captured.\n",
      "154 of 365 samples captured.\n",
      "155 of 365 samples captured.\n",
      "156 of 365 samples captured.\n",
      "157 of 365 samples captured.\n",
      "158 of 365 samples captured.\n",
      "159 of 365 samples captured.\n",
      "160 of 365 samples captured.\n",
      "161 of 365 samples captured.\n",
      "162 of 365 samples captured.\n",
      "163 of 365 samples captured.\n",
      "164 of 365 samples captured.\n",
      "165 of 365 samples captured.\n",
      "166 of 365 samples captured.\n",
      "167 of 365 samples captured.\n",
      "168 of 365 samples captured.\n",
      "169 of 365 samples captured.\n",
      "170 of 365 samples captured.\n",
      "171 of 365 samples captured.\n",
      "172 of 365 samples captured.\n",
      "173 of 365 samples captured.\n",
      "174 of 365 samples captured.\n",
      "175 of 365 samples captured.\n",
      "176 of 365 samples captured.\n",
      "177 of 365 samples captured.\n",
      "178 of 365 samples captured.\n",
      "179 of 365 samples captured.\n",
      "180 of 365 samples captured.\n",
      "181 of 365 samples captured.\n",
      "182 of 365 samples captured.\n",
      "183 of 365 samples captured.\n",
      "184 of 365 samples captured.\n",
      "185 of 365 samples captured.\n",
      "186 of 365 samples captured.\n",
      "187 of 365 samples captured.\n",
      "188 of 365 samples captured.\n",
      "189 of 365 samples captured.\n",
      "190 of 365 samples captured.\n",
      "191 of 365 samples captured.\n",
      "192 of 365 samples captured.\n",
      "193 of 365 samples captured.\n",
      "194 of 365 samples captured.\n",
      "195 of 365 samples captured.\n",
      "196 of 365 samples captured.\n",
      "197 of 365 samples captured.\n",
      "198 of 365 samples captured.\n",
      "199 of 365 samples captured.\n",
      "200 of 365 samples captured.\n",
      "201 of 365 samples captured.\n",
      "202 of 365 samples captured.\n",
      "203 of 365 samples captured.\n",
      "204 of 365 samples captured.\n",
      "205 of 365 samples captured.\n",
      "206 of 365 samples captured.\n",
      "207 of 365 samples captured.\n",
      "208 of 365 samples captured.\n",
      "209 of 365 samples captured.\n",
      "210 of 365 samples captured.\n",
      "211 of 365 samples captured.\n",
      "212 of 365 samples captured.\n",
      "213 of 365 samples captured.\n",
      "214 of 365 samples captured.\n",
      "215 of 365 samples captured.\n",
      "216 of 365 samples captured.\n",
      "217 of 365 samples captured.\n",
      "218 of 365 samples captured.\n",
      "219 of 365 samples captured.\n",
      "220 of 365 samples captured.\n",
      "221 of 365 samples captured.\n",
      "222 of 365 samples captured.\n",
      "223 of 365 samples captured.\n",
      "224 of 365 samples captured.\n",
      "225 of 365 samples captured.\n",
      "226 of 365 samples captured.\n",
      "227 of 365 samples captured.\n",
      "228 of 365 samples captured.\n",
      "229 of 365 samples captured.\n",
      "230 of 365 samples captured.\n",
      "231 of 365 samples captured.\n",
      "232 of 365 samples captured.\n",
      "233 of 365 samples captured.\n",
      "234 of 365 samples captured.\n",
      "235 of 365 samples captured.\n",
      "236 of 365 samples captured.\n",
      "237 of 365 samples captured.\n",
      "238 of 365 samples captured.\n",
      "239 of 365 samples captured.\n",
      "240 of 365 samples captured.\n",
      "241 of 365 samples captured.\n",
      "242 of 365 samples captured.\n",
      "243 of 365 samples captured.\n",
      "244 of 365 samples captured.\n",
      "245 of 365 samples captured.\n",
      "246 of 365 samples captured.\n",
      "247 of 365 samples captured.\n",
      "248 of 365 samples captured.\n",
      "249 of 365 samples captured.\n",
      "250 of 365 samples captured.\n",
      "251 of 365 samples captured.\n",
      "252 of 365 samples captured.\n",
      "253 of 365 samples captured.\n",
      "254 of 365 samples captured.\n",
      "255 of 365 samples captured.\n",
      "256 of 365 samples captured.\n",
      "257 of 365 samples captured.\n",
      "258 of 365 samples captured.\n",
      "259 of 365 samples captured.\n",
      "260 of 365 samples captured.\n",
      "261 of 365 samples captured.\n",
      "262 of 365 samples captured.\n",
      "263 of 365 samples captured.\n",
      "264 of 365 samples captured.\n",
      "265 of 365 samples captured.\n",
      "266 of 365 samples captured.\n",
      "267 of 365 samples captured.\n",
      "268 of 365 samples captured.\n",
      "269 of 365 samples captured.\n",
      "270 of 365 samples captured.\n",
      "271 of 365 samples captured.\n",
      "272 of 365 samples captured.\n",
      "273 of 365 samples captured.\n",
      "274 of 365 samples captured.\n",
      "275 of 365 samples captured.\n",
      "276 of 365 samples captured.\n",
      "277 of 365 samples captured.\n",
      "278 of 365 samples captured.\n",
      "279 of 365 samples captured.\n",
      "280 of 365 samples captured.\n",
      "281 of 365 samples captured.\n",
      "282 of 365 samples captured.\n",
      "283 of 365 samples captured.\n",
      "284 of 365 samples captured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 of 365 samples captured.\n",
      "286 of 365 samples captured.\n",
      "287 of 365 samples captured.\n",
      "288 of 365 samples captured.\n",
      "289 of 365 samples captured.\n",
      "290 of 365 samples captured.\n",
      "291 of 365 samples captured.\n",
      "292 of 365 samples captured.\n",
      "293 of 365 samples captured.\n",
      "294 of 365 samples captured.\n",
      "295 of 365 samples captured.\n",
      "296 of 365 samples captured.\n",
      "297 of 365 samples captured.\n",
      "298 of 365 samples captured.\n",
      "299 of 365 samples captured.\n",
      "300 of 365 samples captured.\n",
      "301 of 365 samples captured.\n",
      "302 of 365 samples captured.\n",
      "303 of 365 samples captured.\n",
      "304 of 365 samples captured.\n",
      "305 of 365 samples captured.\n",
      "306 of 365 samples captured.\n",
      "307 of 365 samples captured.\n",
      "308 of 365 samples captured.\n",
      "309 of 365 samples captured.\n",
      "310 of 365 samples captured.\n",
      "311 of 365 samples captured.\n",
      "312 of 365 samples captured.\n",
      "313 of 365 samples captured.\n",
      "314 of 365 samples captured.\n",
      "315 of 365 samples captured.\n",
      "316 of 365 samples captured.\n",
      "317 of 365 samples captured.\n",
      "318 of 365 samples captured.\n",
      "319 of 365 samples captured.\n",
      "320 of 365 samples captured.\n",
      "321 of 365 samples captured.\n",
      "322 of 365 samples captured.\n",
      "323 of 365 samples captured.\n",
      "324 of 365 samples captured.\n",
      "325 of 365 samples captured.\n",
      "326 of 365 samples captured.\n",
      "327 of 365 samples captured.\n",
      "328 of 365 samples captured.\n",
      "329 of 365 samples captured.\n",
      "330 of 365 samples captured.\n",
      "331 of 365 samples captured.\n",
      "332 of 365 samples captured.\n",
      "333 of 365 samples captured.\n",
      "334 of 365 samples captured.\n",
      "335 of 365 samples captured.\n",
      "336 of 365 samples captured.\n",
      "337 of 365 samples captured.\n",
      "338 of 365 samples captured.\n",
      "339 of 365 samples captured.\n",
      "340 of 365 samples captured.\n",
      "341 of 365 samples captured.\n",
      "342 of 365 samples captured.\n",
      "343 of 365 samples captured.\n",
      "344 of 365 samples captured.\n",
      "345 of 365 samples captured.\n",
      "346 of 365 samples captured.\n",
      "347 of 365 samples captured.\n",
      "348 of 365 samples captured.\n",
      "349 of 365 samples captured.\n",
      "350 of 365 samples captured.\n",
      "351 of 365 samples captured.\n",
      "352 of 365 samples captured.\n",
      "353 of 365 samples captured.\n",
      "354 of 365 samples captured.\n",
      "355 of 365 samples captured.\n",
      "356 of 365 samples captured.\n",
      "357 of 365 samples captured.\n",
      "358 of 365 samples captured.\n",
      "359 of 365 samples captured.\n",
      "360 of 365 samples captured.\n",
      "361 of 365 samples captured.\n",
      "362 of 365 samples captured.\n",
      "363 of 365 samples captured.\n",
      "364 of 365 samples captured.\n",
      "365 of 365 samples captured.\n",
      "We are done here.\n"
     ]
    }
   ],
   "source": [
    "zeno_head = None\n",
    "video_source = None\n",
    "config.read('config.ini')\n",
    "motor_duration = config.getint('zeno_interface', 'motor_duration')\n",
    "grace_period = config.getint('zeno_interface', 'grace_period')\n",
    "try:\n",
    "    # Load configuration related to data collection\n",
    "    sampling_delay = config.getint('prepare_dataset2', 'sampling_delay') / 1000.0 / 2\n",
    "    retry_limit = max(1, config.getint('prepare_dataset2', 'retry_limit'))\n",
    "\n",
    "    # Connect to the robot\n",
    "    zeno_ip_address = config.get('zeno_interface', 'zeno_ip_address')\n",
    "    zeno_head = ZenoHead(zeno_ip_address)\n",
    "    print('Connected to zeno at %s.' % zeno_ip_address)\n",
    "    \n",
    "    # Initialise the tracker\n",
    "    tracker68 = ZenoFaceTracker(os.path.realpath('./models/zeno_landmark_tracker_68.model'), \n",
    "                                os.path.realpath(config.get('facial_landmark_tracker', 'auxiliary_model_path')), \n",
    "                                os.path.realpath('./models/zeno_face_detector.model'))\n",
    "    tracker68.failure_detection_interval = 1\n",
    "    print('Lanmark tracker initialised.')\n",
    "\n",
    "    # Open the video source\n",
    "    video_source_id = config.get('video_source', 'video_source')\n",
    "    frame_width = config.getint('video_source', 'frame_width')\n",
    "    frame_height = config.getint('video_source', 'frame_height')\n",
    "    frame_rate = config.getfloat('video_source', 'frame_rate')\n",
    "    if video_source_id == 'window':\n",
    "        window_title_re = config.get('window_specification', 'title_re')\n",
    "        window_class_name = config.get('window_specification', 'class_name')\n",
    "        child_identifier = config.get('window_specification', 'child_identifier')\n",
    "        window_roi = config.get('window_specification', 'window_roi').replace(\n",
    "            '\\'', '').replace('\\\"', '').replace('\\t', '').replace(' ', '')\n",
    "        window_roi = tuple([float(x) for x in window_roi.split(',') if len(x) > 0])\n",
    "        pywinauto = importlib.import_module('pywinauto')\n",
    "        top_level_window = pywinauto.Desktop(backend='win32').window(title_re=window_title_re,\n",
    "                                                                     class_name=window_class_name,\n",
    "                                                                     visible_only=False)\n",
    "        if len(child_identifier) > 0:\n",
    "            window_handle = top_level_window[child_identifier].handle\n",
    "        else:\n",
    "            window_handle = top_level_window.handle\n",
    "            video_source = ThreadedWindowCapture(window_handle, frame_width, frame_height, \n",
    "                                                 frame_rate, window_roi)\n",
    "            print('Window capture initialised.')\n",
    "    else:\n",
    "        video_source = ThreadedWebcam(int(video_source_id), frame_width, frame_height, frame_rate)\n",
    "        print('Webcam #%d opened.' % int(video_source_id))\n",
    "    \n",
    "    # The processing loop\n",
    "    cv2.namedWindow('68 landmark model', cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_KEEPRATIO)\n",
    "    cv2.resizeWindow('68 landmark model', (frame_width, frame_height))    \n",
    "    for idx, sample in enumerate(ck_data):\n",
    "        cv2.imshow('source', cv2.imread(os.path.splitext(sample['image_file'])[0] + '_rendering.png'))\n",
    "        zeno_head.move(np.clip(sample['actuator_values'], 0.0, 1.0), motor_duration)\n",
    "        last_move_time = time.time()\n",
    "        retries = 0\n",
    "        while cv2.getWindowProperty('68 landmark model', 0) >= 0:\n",
    "            is_new_frame, frame = video_source.read(0.01)\n",
    "            if is_new_frame:\n",
    "                if frame is None:\n",
    "                    break\n",
    "                else:\n",
    "                    tracker68.track(frame)\n",
    "                    rendering = frame.copy()\n",
    "                    tracker68.plot_current_result(rendering, plot_head_pose=False)\n",
    "                    cv2.imshow('68 landmark model', rendering)\n",
    "                    time_elapsed = time.time() - last_move_time\n",
    "                    if time_elapsed >= sampling_delay:\n",
    "                        if tracker68.has_facial_landmarks:\n",
    "                            sample['zeno_eye_points'] = tracker68.eye_landmarks\n",
    "                            sample['zeno_landmarks'] = tracker68.facial_landmarks\n",
    "                            cv2.imwrite(os.path.splitext(sample['image_file'])[0] + '_zeno.png', frame)\n",
    "                            cv2.imwrite(os.path.splitext(sample['image_file'])[0] + '_zeno_rendering.png', rendering)\n",
    "                            print('%d of %d samples captured.' % (idx + 1, len(ck_data)))\n",
    "                        else:\n",
    "                            retries = retries + 1\n",
    "                        if tracker68.has_facial_landmarks or retries >= retry_limit:\n",
    "                            break\n",
    "                    elif time_elapsed >= motor_duration / 1000.0:\n",
    "                        # Hold current position\n",
    "                        zeno_head.move(np.clip(sample['actuator_values'], 0.0, 1.0), 40)\n",
    "            cv2.waitKey(10)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    if video_source is not None:\n",
    "        video_source.release()\n",
    "    if zeno_head is not None:\n",
    "        zeno_head.reset(motor_duration)\n",
    "        time.sleep(max(motor_duration, grace_period) / 1000.0)\n",
    "        zeno_head.disconnect()\n",
    "    print('We are done here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to zeno at 127.0.0.1.\n",
      "Lanmark tracker initialised.\n",
      "Webcam #0 opened.\n",
      "1 of 365 samples captured.\n",
      "2 of 365 samples captured.\n",
      "3 of 365 samples captured.\n",
      "4 of 365 samples captured.\n",
      "5 of 365 samples captured.\n",
      "6 of 365 samples captured.\n",
      "7 of 365 samples captured.\n",
      "8 of 365 samples captured.\n",
      "9 of 365 samples captured.\n",
      "10 of 365 samples captured.\n",
      "11 of 365 samples captured.\n",
      "12 of 365 samples captured.\n",
      "13 of 365 samples captured.\n",
      "14 of 365 samples captured.\n",
      "15 of 365 samples captured.\n",
      "16 of 365 samples captured.\n",
      "17 of 365 samples captured.\n",
      "18 of 365 samples captured.\n",
      "19 of 365 samples captured.\n",
      "20 of 365 samples captured.\n",
      "21 of 365 samples captured.\n",
      "22 of 365 samples captured.\n",
      "23 of 365 samples captured.\n",
      "24 of 365 samples captured.\n",
      "25 of 365 samples captured.\n",
      "26 of 365 samples captured.\n",
      "27 of 365 samples captured.\n",
      "28 of 365 samples captured.\n",
      "29 of 365 samples captured.\n",
      "30 of 365 samples captured.\n",
      "31 of 365 samples captured.\n",
      "32 of 365 samples captured.\n",
      "33 of 365 samples captured.\n",
      "34 of 365 samples captured.\n",
      "35 of 365 samples captured.\n",
      "36 of 365 samples captured.\n",
      "37 of 365 samples captured.\n",
      "38 of 365 samples captured.\n",
      "39 of 365 samples captured.\n",
      "40 of 365 samples captured.\n",
      "41 of 365 samples captured.\n",
      "42 of 365 samples captured.\n",
      "43 of 365 samples captured.\n",
      "44 of 365 samples captured.\n",
      "45 of 365 samples captured.\n",
      "46 of 365 samples captured.\n",
      "47 of 365 samples captured.\n",
      "48 of 365 samples captured.\n",
      "49 of 365 samples captured.\n",
      "50 of 365 samples captured.\n",
      "51 of 365 samples captured.\n",
      "52 of 365 samples captured.\n",
      "53 of 365 samples captured.\n",
      "54 of 365 samples captured.\n",
      "55 of 365 samples captured.\n",
      "56 of 365 samples captured.\n",
      "57 of 365 samples captured.\n",
      "58 of 365 samples captured.\n",
      "59 of 365 samples captured.\n",
      "60 of 365 samples captured.\n",
      "61 of 365 samples captured.\n",
      "62 of 365 samples captured.\n",
      "63 of 365 samples captured.\n",
      "64 of 365 samples captured.\n",
      "65 of 365 samples captured.\n",
      "66 of 365 samples captured.\n",
      "67 of 365 samples captured.\n",
      "68 of 365 samples captured.\n",
      "69 of 365 samples captured.\n",
      "70 of 365 samples captured.\n",
      "71 of 365 samples captured.\n",
      "72 of 365 samples captured.\n",
      "73 of 365 samples captured.\n",
      "74 of 365 samples captured.\n",
      "75 of 365 samples captured.\n",
      "76 of 365 samples captured.\n",
      "77 of 365 samples captured.\n",
      "78 of 365 samples captured.\n",
      "79 of 365 samples captured.\n",
      "80 of 365 samples captured.\n",
      "81 of 365 samples captured.\n",
      "82 of 365 samples captured.\n",
      "83 of 365 samples captured.\n",
      "84 of 365 samples captured.\n",
      "85 of 365 samples captured.\n",
      "86 of 365 samples captured.\n",
      "87 of 365 samples captured.\n",
      "88 of 365 samples captured.\n",
      "89 of 365 samples captured.\n",
      "90 of 365 samples captured.\n",
      "91 of 365 samples captured.\n",
      "92 of 365 samples captured.\n",
      "93 of 365 samples captured.\n",
      "94 of 365 samples captured.\n",
      "95 of 365 samples captured.\n",
      "96 of 365 samples captured.\n",
      "97 of 365 samples captured.\n",
      "98 of 365 samples captured.\n",
      "99 of 365 samples captured.\n",
      "100 of 365 samples captured.\n",
      "101 of 365 samples captured.\n",
      "102 of 365 samples captured.\n",
      "103 of 365 samples captured.\n",
      "104 of 365 samples captured.\n",
      "105 of 365 samples captured.\n",
      "106 of 365 samples captured.\n",
      "107 of 365 samples captured.\n",
      "108 of 365 samples captured.\n",
      "109 of 365 samples captured.\n",
      "110 of 365 samples captured.\n",
      "111 of 365 samples captured.\n",
      "112 of 365 samples captured.\n",
      "113 of 365 samples captured.\n",
      "114 of 365 samples captured.\n",
      "115 of 365 samples captured.\n",
      "116 of 365 samples captured.\n",
      "117 of 365 samples captured.\n",
      "118 of 365 samples captured.\n",
      "119 of 365 samples captured.\n",
      "120 of 365 samples captured.\n",
      "121 of 365 samples captured.\n",
      "122 of 365 samples captured.\n",
      "123 of 365 samples captured.\n",
      "124 of 365 samples captured.\n",
      "125 of 365 samples captured.\n",
      "126 of 365 samples captured.\n",
      "127 of 365 samples captured.\n",
      "128 of 365 samples captured.\n",
      "129 of 365 samples captured.\n",
      "130 of 365 samples captured.\n",
      "131 of 365 samples captured.\n",
      "132 of 365 samples captured.\n",
      "133 of 365 samples captured.\n",
      "134 of 365 samples captured.\n",
      "135 of 365 samples captured.\n",
      "136 of 365 samples captured.\n",
      "137 of 365 samples captured.\n",
      "138 of 365 samples captured.\n",
      "139 of 365 samples captured.\n",
      "140 of 365 samples captured.\n",
      "141 of 365 samples captured.\n",
      "142 of 365 samples captured.\n",
      "143 of 365 samples captured.\n",
      "144 of 365 samples captured.\n",
      "145 of 365 samples captured.\n",
      "146 of 365 samples captured.\n",
      "147 of 365 samples captured.\n",
      "148 of 365 samples captured.\n",
      "149 of 365 samples captured.\n",
      "150 of 365 samples captured.\n",
      "151 of 365 samples captured.\n",
      "152 of 365 samples captured.\n",
      "153 of 365 samples captured.\n",
      "154 of 365 samples captured.\n",
      "155 of 365 samples captured.\n",
      "156 of 365 samples captured.\n",
      "157 of 365 samples captured.\n",
      "158 of 365 samples captured.\n",
      "159 of 365 samples captured.\n",
      "160 of 365 samples captured.\n",
      "161 of 365 samples captured.\n",
      "162 of 365 samples captured.\n",
      "163 of 365 samples captured.\n",
      "164 of 365 samples captured.\n",
      "165 of 365 samples captured.\n",
      "166 of 365 samples captured.\n",
      "167 of 365 samples captured.\n",
      "168 of 365 samples captured.\n",
      "169 of 365 samples captured.\n",
      "170 of 365 samples captured.\n",
      "171 of 365 samples captured.\n",
      "172 of 365 samples captured.\n",
      "173 of 365 samples captured.\n",
      "174 of 365 samples captured.\n",
      "175 of 365 samples captured.\n",
      "176 of 365 samples captured.\n",
      "177 of 365 samples captured.\n",
      "178 of 365 samples captured.\n",
      "179 of 365 samples captured.\n",
      "180 of 365 samples captured.\n",
      "181 of 365 samples captured.\n",
      "182 of 365 samples captured.\n",
      "183 of 365 samples captured.\n",
      "184 of 365 samples captured.\n",
      "185 of 365 samples captured.\n",
      "186 of 365 samples captured.\n",
      "187 of 365 samples captured.\n",
      "188 of 365 samples captured.\n",
      "189 of 365 samples captured.\n",
      "190 of 365 samples captured.\n",
      "191 of 365 samples captured.\n",
      "192 of 365 samples captured.\n",
      "193 of 365 samples captured.\n",
      "194 of 365 samples captured.\n",
      "195 of 365 samples captured.\n",
      "196 of 365 samples captured.\n",
      "197 of 365 samples captured.\n",
      "198 of 365 samples captured.\n",
      "199 of 365 samples captured.\n",
      "200 of 365 samples captured.\n",
      "201 of 365 samples captured.\n",
      "202 of 365 samples captured.\n",
      "203 of 365 samples captured.\n",
      "204 of 365 samples captured.\n",
      "205 of 365 samples captured.\n",
      "206 of 365 samples captured.\n",
      "207 of 365 samples captured.\n",
      "208 of 365 samples captured.\n",
      "209 of 365 samples captured.\n",
      "210 of 365 samples captured.\n",
      "211 of 365 samples captured.\n",
      "212 of 365 samples captured.\n",
      "213 of 365 samples captured.\n",
      "214 of 365 samples captured.\n",
      "215 of 365 samples captured.\n",
      "216 of 365 samples captured.\n",
      "217 of 365 samples captured.\n",
      "218 of 365 samples captured.\n",
      "219 of 365 samples captured.\n",
      "220 of 365 samples captured.\n",
      "221 of 365 samples captured.\n",
      "222 of 365 samples captured.\n",
      "223 of 365 samples captured.\n",
      "224 of 365 samples captured.\n",
      "225 of 365 samples captured.\n",
      "226 of 365 samples captured.\n",
      "227 of 365 samples captured.\n",
      "228 of 365 samples captured.\n",
      "229 of 365 samples captured.\n",
      "230 of 365 samples captured.\n",
      "231 of 365 samples captured.\n",
      "232 of 365 samples captured.\n",
      "233 of 365 samples captured.\n",
      "234 of 365 samples captured.\n",
      "235 of 365 samples captured.\n",
      "236 of 365 samples captured.\n",
      "237 of 365 samples captured.\n",
      "238 of 365 samples captured.\n",
      "239 of 365 samples captured.\n",
      "240 of 365 samples captured.\n",
      "241 of 365 samples captured.\n",
      "242 of 365 samples captured.\n",
      "243 of 365 samples captured.\n",
      "244 of 365 samples captured.\n",
      "245 of 365 samples captured.\n",
      "246 of 365 samples captured.\n",
      "247 of 365 samples captured.\n",
      "248 of 365 samples captured.\n",
      "249 of 365 samples captured.\n",
      "250 of 365 samples captured.\n",
      "251 of 365 samples captured.\n",
      "252 of 365 samples captured.\n",
      "253 of 365 samples captured.\n",
      "254 of 365 samples captured.\n",
      "255 of 365 samples captured.\n",
      "256 of 365 samples captured.\n",
      "257 of 365 samples captured.\n",
      "258 of 365 samples captured.\n",
      "259 of 365 samples captured.\n",
      "260 of 365 samples captured.\n",
      "261 of 365 samples captured.\n",
      "262 of 365 samples captured.\n",
      "263 of 365 samples captured.\n",
      "264 of 365 samples captured.\n",
      "265 of 365 samples captured.\n",
      "266 of 365 samples captured.\n",
      "267 of 365 samples captured.\n",
      "268 of 365 samples captured.\n",
      "269 of 365 samples captured.\n",
      "270 of 365 samples captured.\n",
      "271 of 365 samples captured.\n",
      "272 of 365 samples captured.\n",
      "273 of 365 samples captured.\n",
      "274 of 365 samples captured.\n",
      "275 of 365 samples captured.\n",
      "276 of 365 samples captured.\n",
      "277 of 365 samples captured.\n",
      "278 of 365 samples captured.\n",
      "279 of 365 samples captured.\n",
      "280 of 365 samples captured.\n",
      "281 of 365 samples captured.\n",
      "282 of 365 samples captured.\n",
      "283 of 365 samples captured.\n",
      "284 of 365 samples captured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 of 365 samples captured.\n",
      "286 of 365 samples captured.\n",
      "287 of 365 samples captured.\n",
      "288 of 365 samples captured.\n",
      "289 of 365 samples captured.\n",
      "290 of 365 samples captured.\n",
      "291 of 365 samples captured.\n",
      "292 of 365 samples captured.\n",
      "293 of 365 samples captured.\n",
      "294 of 365 samples captured.\n",
      "295 of 365 samples captured.\n",
      "296 of 365 samples captured.\n",
      "297 of 365 samples captured.\n",
      "298 of 365 samples captured.\n",
      "299 of 365 samples captured.\n",
      "300 of 365 samples captured.\n",
      "301 of 365 samples captured.\n",
      "302 of 365 samples captured.\n",
      "303 of 365 samples captured.\n",
      "304 of 365 samples captured.\n",
      "305 of 365 samples captured.\n",
      "306 of 365 samples captured.\n",
      "307 of 365 samples captured.\n",
      "308 of 365 samples captured.\n",
      "309 of 365 samples captured.\n",
      "310 of 365 samples captured.\n",
      "311 of 365 samples captured.\n",
      "312 of 365 samples captured.\n",
      "313 of 365 samples captured.\n",
      "314 of 365 samples captured.\n",
      "315 of 365 samples captured.\n",
      "316 of 365 samples captured.\n",
      "317 of 365 samples captured.\n",
      "318 of 365 samples captured.\n",
      "319 of 365 samples captured.\n",
      "320 of 365 samples captured.\n",
      "321 of 365 samples captured.\n",
      "322 of 365 samples captured.\n",
      "323 of 365 samples captured.\n",
      "324 of 365 samples captured.\n",
      "325 of 365 samples captured.\n",
      "326 of 365 samples captured.\n",
      "327 of 365 samples captured.\n",
      "328 of 365 samples captured.\n",
      "329 of 365 samples captured.\n",
      "330 of 365 samples captured.\n",
      "331 of 365 samples captured.\n",
      "332 of 365 samples captured.\n",
      "333 of 365 samples captured.\n",
      "334 of 365 samples captured.\n",
      "335 of 365 samples captured.\n",
      "336 of 365 samples captured.\n",
      "337 of 365 samples captured.\n",
      "338 of 365 samples captured.\n",
      "339 of 365 samples captured.\n",
      "340 of 365 samples captured.\n",
      "341 of 365 samples captured.\n",
      "342 of 365 samples captured.\n",
      "343 of 365 samples captured.\n",
      "344 of 365 samples captured.\n",
      "345 of 365 samples captured.\n",
      "346 of 365 samples captured.\n",
      "347 of 365 samples captured.\n",
      "348 of 365 samples captured.\n",
      "349 of 365 samples captured.\n",
      "350 of 365 samples captured.\n",
      "351 of 365 samples captured.\n",
      "352 of 365 samples captured.\n",
      "353 of 365 samples captured.\n",
      "354 of 365 samples captured.\n",
      "355 of 365 samples captured.\n",
      "356 of 365 samples captured.\n",
      "357 of 365 samples captured.\n",
      "358 of 365 samples captured.\n",
      "359 of 365 samples captured.\n",
      "360 of 365 samples captured.\n",
      "361 of 365 samples captured.\n",
      "362 of 365 samples captured.\n",
      "363 of 365 samples captured.\n",
      "364 of 365 samples captured.\n",
      "365 of 365 samples captured.\n",
      "We are done here.\n"
     ]
    }
   ],
   "source": [
    "helper = ZenoHeadImitationHelper()\n",
    "\n",
    "zeno_head = None\n",
    "video_source = None\n",
    "config.read('config.ini')\n",
    "motor_duration = config.getint('zeno_interface', 'motor_duration')\n",
    "grace_period = config.getint('zeno_interface', 'grace_period')\n",
    "try:\n",
    "    # Load configuration related to data collection\n",
    "    sampling_delay = config.getint('prepare_dataset2', 'sampling_delay') / 1000.0 / 2\n",
    "    retry_limit = max(1, config.getint('prepare_dataset2', 'retry_limit'))\n",
    "\n",
    "    # Connect to the robot\n",
    "    zeno_ip_address = config.get('zeno_interface', 'zeno_ip_address')\n",
    "    zeno_head = ZenoHead(zeno_ip_address)\n",
    "    print('Connected to zeno at %s.' % zeno_ip_address)\n",
    "    \n",
    "    # Initialise the tracker\n",
    "    tracker68 = ZenoFaceTracker(os.path.realpath('./models/zeno_landmark_tracker_68.model'), \n",
    "                                os.path.realpath(config.get('facial_landmark_tracker', 'auxiliary_model_path')), \n",
    "                                os.path.realpath('./models/zeno_face_detector.model'))\n",
    "    tracker68.failure_detection_interval = 1\n",
    "    print('Lanmark tracker initialised.')\n",
    "\n",
    "    # Open the video source\n",
    "    video_source_id = config.get('video_source', 'video_source')\n",
    "    frame_width = config.getint('video_source', 'frame_width')\n",
    "    frame_height = config.getint('video_source', 'frame_height')\n",
    "    frame_rate = config.getfloat('video_source', 'frame_rate')\n",
    "    if video_source_id == 'window':\n",
    "        window_title_re = config.get('window_specification', 'title_re')\n",
    "        window_class_name = config.get('window_specification', 'class_name')\n",
    "        child_identifier = config.get('window_specification', 'child_identifier')\n",
    "        window_roi = config.get('window_specification', 'window_roi').replace(\n",
    "            '\\'', '').replace('\\\"', '').replace('\\t', '').replace(' ', '')\n",
    "        window_roi = tuple([float(x) for x in window_roi.split(',') if len(x) > 0])\n",
    "        pywinauto = importlib.import_module('pywinauto')\n",
    "        top_level_window = pywinauto.Desktop(backend='win32').window(title_re=window_title_re,\n",
    "                                                                     class_name=window_class_name,\n",
    "                                                                     visible_only=False)\n",
    "        if len(child_identifier) > 0:\n",
    "            window_handle = top_level_window[child_identifier].handle\n",
    "        else:\n",
    "            window_handle = top_level_window.handle\n",
    "            video_source = ThreadedWindowCapture(window_handle, frame_width, frame_height, \n",
    "                                                 frame_rate, window_roi)\n",
    "            print('Window capture initialised.')\n",
    "    else:\n",
    "        video_source = ThreadedWebcam(int(video_source_id), frame_width, frame_height, frame_rate)\n",
    "        print('Webcam #%d opened.' % int(video_source_id))\n",
    "    \n",
    "    # The processing loop\n",
    "    cv2.namedWindow('68 landmark model', cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_KEEPRATIO)\n",
    "    cv2.resizeWindow('68 landmark model', (frame_width, frame_height))    \n",
    "    for idx, sample in enumerate(ck_data):\n",
    "        cv2.imshow('source', cv2.imread(os.path.splitext(sample['image_file'])[0] + '_rendering.png'))\n",
    "        acutator_values = helper.calculate_motor_positions(sample['landmarks'], \n",
    "                                                           sample['eye_points'], \n",
    "                                                           sample['head_pose'][0], \n",
    "                                                           sample['head_pose'][1], \n",
    "                                                           sample['head_pose'][2])\n",
    "        zeno_head.move(acutator_values, motor_duration)\n",
    "        last_move_time = time.time()\n",
    "        retries = 0\n",
    "        while cv2.getWindowProperty('68 landmark model', 0) >= 0:\n",
    "            is_new_frame, frame = video_source.read(0.01)\n",
    "            if is_new_frame:\n",
    "                if frame is None:\n",
    "                    break\n",
    "                else:\n",
    "                    tracker68.track(frame)\n",
    "                    rendering = frame.copy()\n",
    "                    tracker68.plot_current_result(rendering, plot_head_pose=False)\n",
    "                    cv2.imshow('68 landmark model', rendering)\n",
    "                    time_elapsed = time.time() - last_move_time\n",
    "                    if time_elapsed >= sampling_delay:\n",
    "                        if tracker68.has_facial_landmarks:\n",
    "                            sample['old_zeno_eye_points'] = tracker68.eye_landmarks\n",
    "                            sample['old_zeno_landmarks'] = tracker68.facial_landmarks\n",
    "                            sample['old_actuator_values'] = acutator_values[:]\n",
    "                            cv2.imwrite(os.path.splitext(sample['image_file'])[0] + '_old_zeno.png', frame)\n",
    "                            cv2.imwrite(os.path.splitext(sample['image_file'])[0] + '_old_zeno_rendering.png', rendering)\n",
    "                            print('%d of %d samples captured.' % (idx + 1, len(ck_data)))\n",
    "                        else:\n",
    "                            retries = retries + 1\n",
    "                        if tracker68.has_facial_landmarks or retries >= retry_limit:\n",
    "                            break\n",
    "                    elif time_elapsed >= motor_duration / 1000.0:\n",
    "                        # Hold current position\n",
    "                        acutator_values = helper.calculate_motor_positions(sample['landmarks'], \n",
    "                                                                           sample['eye_points'], \n",
    "                                                                           sample['head_pose'][0], \n",
    "                                                                           sample['head_pose'][1], \n",
    "                                                                           sample['head_pose'][2])\n",
    "                        zeno_head.move(acutator_values, 40)\n",
    "            cv2.waitKey(10)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    if video_source is not None:\n",
    "        video_source.release()\n",
    "    if zeno_head is not None:\n",
    "        zeno_head.reset(motor_duration)\n",
    "        time.sleep(max(motor_duration, grace_period) / 1000.0)\n",
    "        zeno_head.disconnect()\n",
    "    print('We are done here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ck_data).to_pickle('ck_data.pkl', protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_box(landmarks, margin=(0.0, 0.0, 0.0, 0.0), exclude_chin_points=False):\n",
    "    # Get bounding box\n",
    "    if exclude_chin_points and landmarks.shape[0] == 68:\n",
    "        top_left = np.min(landmarks[17:], axis=0)\n",
    "        bottom_right = np.max(landmarks[17:], axis=0)\n",
    "    else:\n",
    "        top_left = np.min(landmarks, axis=0)\n",
    "        bottom_right = np.max(landmarks, axis=0)\n",
    "    face_size = bottom_right - top_left\n",
    "    top_left[0] = np.floor(top_left[0] - face_size[0] * margin[0])\n",
    "    top_left[1] = np.floor(top_left[1] - face_size[1] * margin[1])\n",
    "    bottom_right[0] = np.ceil(bottom_right[0] + face_size[0] * margin[2])\n",
    "    bottom_right[1] = np.ceil(bottom_right[1] + face_size[1] * margin[3])\n",
    "\n",
    "    # Make face box square\n",
    "    difference = (bottom_right[1] - top_left[1] + 1) - (bottom_right[0] - top_left[0] + 1)\n",
    "    if difference > 0:\n",
    "        top_left[0] -= difference // 2\n",
    "        bottom_right[0] += difference - difference // 2\n",
    "    elif difference < 0:\n",
    "        difference = -difference\n",
    "        top_left[1] -= difference // 2\n",
    "        bottom_right[1] += difference - difference // 2\n",
    "\n",
    "    return top_left, bottom_right\n",
    "\n",
    "\n",
    "def extract_face_image(image, landmarks, target_size, margin, head_pose=None,\n",
    "                       eye_points=None, exclude_chin_points=False,\n",
    "                       interpolation=cv2.INTER_CUBIC):\n",
    "    # First, see whether we have head pose\n",
    "    if head_pose is not None and len(head_pose) >= 3:\n",
    "        roll = head_pose[2]\n",
    "    else:\n",
    "        roll = None\n",
    "\n",
    "    # Get a proper bounding box for the face\n",
    "    if margin is None:\n",
    "        margin = (0.0, 0.0, 0.0, 0.0)\n",
    "    if roll is None:\n",
    "        top_left, bottom_right = get_face_box(landmarks, margin, exclude_chin_points)\n",
    "    else:\n",
    "        rotated_landmarks = cv2.getRotationMatrix2D((0, 0), roll, 1.0).dot(\n",
    "            np.vstack((landmarks.T, np.ones(landmarks.shape[0])))).T\n",
    "        top_left, bottom_right = get_face_box(rotated_landmarks, margin, exclude_chin_points)\n",
    "        corners = np.array([[top_left[0], top_left[1], 1],\n",
    "                            [bottom_right[0], top_left[1], 1],\n",
    "                            [bottom_right[0], bottom_right[1], 1],\n",
    "                            [top_left[0], bottom_right[1], 1]])\n",
    "        top_left, bottom_right = get_face_box(cv2.getRotationMatrix2D(\n",
    "            (0, 0), -roll, 1.0).dot(corners.T).T, (0, 0, 0, 0), exclude_chin_points)\n",
    "        top_left -= 5\n",
    "        bottom_right += 5\n",
    "\n",
    "    # Enlarge the image if necessary\n",
    "    padding = np.zeros((image.ndim, 2), dtype=int)\n",
    "    if top_left[0] < 0:\n",
    "        padding[1][0] = -int(top_left[0])\n",
    "    if top_left[1] < 0:\n",
    "        padding[0][0] = -int(top_left[1])\n",
    "    if bottom_right[0] >= image.shape[1]:\n",
    "        padding[1][1] = int(bottom_right[0] - image.shape[1] + 1)\n",
    "    if bottom_right[1] >= image.shape[0]:\n",
    "        padding[0][1] = int(bottom_right[1] - image.shape[0] + 1)\n",
    "    image = np.pad(image, padding, 'symmetric')\n",
    "\n",
    "    # Revise bounding box and landmarks accordingly\n",
    "    landmarks = landmarks.copy()\n",
    "    if eye_points is not None:\n",
    "        eye_points = eye_points.copy()\n",
    "    if top_left[0] < 0:\n",
    "        bottom_right[0] -= top_left[0]\n",
    "        landmarks[:, 0] -= top_left[0]\n",
    "        if eye_points is not None:\n",
    "            eye_points[:, 0] -= top_left[0]\n",
    "        top_left[0] = 0\n",
    "    if top_left[1] < 0:\n",
    "        bottom_right[1] -= top_left[1]\n",
    "        landmarks[:, 1] -= top_left[1]\n",
    "        if eye_points is not None:\n",
    "            eye_points[:, 1] -= top_left[1]\n",
    "        top_left[1] = 0\n",
    "\n",
    "    # Extract the face image\n",
    "    face_image = image[int(top_left[1]): int(bottom_right[1] + 1),\n",
    "                       int(top_left[0]): int(bottom_right[0] + 1)]\n",
    "    landmarks[:, 0] -= top_left[0]\n",
    "    landmarks[:, 1] -= top_left[1]\n",
    "    if eye_points is not None:\n",
    "        eye_points[:, 0] -= top_left[0]\n",
    "        eye_points[:, 1] -= top_left[1]\n",
    "\n",
    "    # If head pose is given, rotate everything\n",
    "    if roll is not None:\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(((face_image.shape[1] - 1) / 2.0,\n",
    "                                                   (face_image.shape[0] - 1) / 2.0), roll, 1.0)\n",
    "        face_image = cv2.warpAffine(face_image, rotation_matrix,\n",
    "                                    dsize=(face_image.shape[1], face_image.shape[0]),\n",
    "                                    flags=(interpolation + cv2.WARP_FILL_OUTLIERS))\n",
    "        landmarks = rotation_matrix.dot(np.vstack((landmarks.T, np.ones(landmarks.shape[0])))).T\n",
    "        if eye_points is not None:\n",
    "            eye_points = rotation_matrix.dot(np.vstack((eye_points.T, np.ones(eye_points.shape[0])))).T\n",
    "        top_left, bottom_right = get_face_box(landmarks, margin, exclude_chin_points)\n",
    "        if top_left[0] > 0:\n",
    "            landmarks[:, 0] -= top_left[0]\n",
    "            if eye_points is not None:\n",
    "                eye_points[:, 0] -= top_left[0]\n",
    "        if top_left[1] > 0:\n",
    "            landmarks[:, 1] -= top_left[1]\n",
    "            if eye_points is not None:\n",
    "                eye_points[:, 1] -= top_left[1]\n",
    "        face_image = face_image[max(int(top_left[1]), 0): min(int(bottom_right[1] + 1), face_image.shape[0]),\n",
    "                                max(int(top_left[0]), 0): min(int(bottom_right[0] + 1), face_image.shape[1])]\n",
    "\n",
    "    # Rescale landmarks and face image\n",
    "    if target_size is not None and target_size[0] > 0 and target_size[1] > 0:\n",
    "        landmarks[:, 0] *= float(target_size[0]) / max(face_image.shape[1], 1)\n",
    "        landmarks[:, 1] *= float(target_size[1]) / max(face_image.shape[0], 1)\n",
    "        if eye_points is not None:\n",
    "            eye_points[:, 0] *= float(target_size[0]) / max(face_image.shape[1], 1)\n",
    "            eye_points[:, 1] *= float(target_size[1]) / max(face_image.shape[0], 1)\n",
    "        face_image = cv2.resize(face_image, target_size, interpolation=interpolation)\n",
    "    else:\n",
    "        face_image = face_image.copy()\n",
    "\n",
    "    return face_image, landmarks, eye_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra face images from the recording\n",
    "for sample in ck_data:\n",
    "    \n",
    "    new_face_file = sample['image_file'].replace('sorted_set_testing', 'sorted_set_testing_zeno')\n",
    "    new_face_folder = os.path.dirname(new_face_file)\n",
    "    if not os.path.exists(new_face_folder):\n",
    "        os.makedirs(new_face_folder)\n",
    "    image = cv2.imread(os.path.splitext(sample['image_file'])[0] + '_zeno.png')\n",
    "    new_face = extract_face_image(image, sample['zeno_landmarks'], (300, 300), (0.05, 0.1, 0.05, 0.1))[0]\n",
    "    cv2.imwrite(new_face_file, new_face)\n",
    "    \n",
    "    old_face_file = sample['image_file'].replace('sorted_set_testing', 'sorted_set_testing_zeno_old')\n",
    "    old_face_folder = os.path.dirname(old_face_file)\n",
    "    if not os.path.exists(old_face_folder):\n",
    "        os.makedirs(old_face_folder)\n",
    "    image = cv2.imread(os.path.splitext(sample['image_file'])[0] + '_old_zeno.png')\n",
    "    old_face = extract_face_image(image, sample['old_zeno_landmarks'], (300, 300), (0.05, 0.1, 0.05, 0.1))[0]\n",
    "    cv2.imwrite(old_face_file, old_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare displacement?\n",
    "for sample in ck_data:\n",
    "    \n",
    "    # Calculate displacement on human face\n",
    "    left_iris = sample['eye_points'][1:6].mean(axis=0)\n",
    "    right_iris = sample['eye_points'][8:13].mean(axis=0)\n",
    "    all_landmarks = np.vstack((sample['landmarks'], left_iris, right_iris))\n",
    "    transform = compute_rigid_alignment_parameters(all_landmarks[anchors], \n",
    "                                                   model['mean_shape'][anchors])\n",
    "    aligned_landmarks = apply_rigid_alignment_parameters(all_landmarks, *transform)\n",
    "    sample['displacement'] = aligned_landmarks - model['neutral_shape']\n",
    "    \n",
    "    # Calculate displacement on zeno face\n",
    "    left_iris = sample['zeno_eye_points'][1:6].mean(axis=0)\n",
    "    right_iris = sample['zeno_eye_points'][8:13].mean(axis=0)\n",
    "    all_landmarks = np.vstack((sample['zeno_landmarks'], left_iris, right_iris))\n",
    "    transform = compute_rigid_alignment_parameters(all_landmarks[anchors], \n",
    "                                                   model['zeno_mean_shape'][anchors])\n",
    "    aligned_landmarks = apply_rigid_alignment_parameters(all_landmarks, *transform)\n",
    "    sample['zeno_displacement'] = aligned_landmarks - model['zeno_neutral_shape']\n",
    "    sample['zeno_displacement_difference'] = np.mean([np.linalg.norm(x) for x in \n",
    "                                                      sample['zeno_displacement'] - \n",
    "                                                      sample['displacement']])\n",
    "    \n",
    "    # Calculate displacement on zeno face for the old method\n",
    "    left_iris = sample['old_zeno_eye_points'][1:6].mean(axis=0)\n",
    "    right_iris = sample['old_zeno_eye_points'][8:13].mean(axis=0)\n",
    "    all_landmarks = np.vstack((sample['old_zeno_landmarks'], left_iris, right_iris))\n",
    "    transform = compute_rigid_alignment_parameters(all_landmarks[anchors], \n",
    "                                                   model['zeno_mean_shape'][anchors])\n",
    "    aligned_landmarks = apply_rigid_alignment_parameters(all_landmarks, *transform)\n",
    "    sample['old_zeno_displacement'] = aligned_landmarks - model['zeno_neutral_shape']\n",
    "    sample['old_zeno_displacement_difference'] = np.mean([np.linalg.norm(x) for x in \n",
    "                                                          sample['old_zeno_displacement'] - \n",
    "                                                          sample['displacement']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeno_d_outer = np.linalg.norm(model['zeno_neutral_shape'][36] - model['zeno_neutral_shape'][45])\n",
    "new_displacement_error = [x['zeno_displacement_difference'] / zeno_d_outer * 85.0 for x in ck_data]\n",
    "old_displacement_error = [x['old_zeno_displacement_difference'] / zeno_d_outer * 85.0 for x in ck_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8301009082419992\n",
      "0.6684607259245723\n",
      "2.9131986870210227\n",
      "0.8180639220572737\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [8, 5]\n",
    "\n",
    "plt.plot(sorted(new_displacement_error), np.arange(len(new_displacement_error)) / \n",
    "         float(len(new_displacement_error)), label='automatic imitation')\n",
    "plt.plot(sorted(old_displacement_error), np.arange(len(old_displacement_error)) / \n",
    "         float(len(old_displacement_error)), label='heuristic rules')\n",
    "plt.legend()\n",
    "plt.grid(which='both')\n",
    "plt.xlabel('normalised landmark displacement error (mm)')\n",
    "plt.ylabel('sample proportion')\n",
    "plt.show()\n",
    "\n",
    "print(np.mean(new_displacement_error))\n",
    "print(np.std(lala1) / zeno_d_outer * 85)\n",
    "\n",
    "print(np.mean(lala2) / zeno_d_outer * 85)\n",
    "print(np.std(lala2) / zeno_d_outer * 85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5504235530492284"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeno_d_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
